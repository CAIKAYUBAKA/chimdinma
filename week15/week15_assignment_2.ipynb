{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAIKAYUBAKA/hds5210-2023/blob/main/week15/week15_assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-fc1c39d0d6f8b82a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "jlvTEY-xiidZ"
      },
      "source": [
        "# Week 15 Programming Assignment\n",
        "\n",
        "The final thing for this semester that we haven't exercised, yet, is working with databases through Python.  In thi final assignment of the semester, you will practice pulling data from either Google Big Query or Snowflake, loading that data into a Pandas data frame, summarizing the data, and then exporting that to an Excel file.\n",
        "\n",
        "**You will need to use your own Google Big Query or Snowflake account to run this notebook, but you should try to make it configurable so anyone with an account in those technologies could run your notebook with minimal changes.**\n",
        "\n",
        "\n",
        "Build a notebook with good comments (either in code or in markdown cells).  Then submit your assignment as usual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm-3FSPAiidb"
      },
      "source": [
        "### 1. Connect to the data source\n",
        "\n",
        "Follow the examples provided in the [week15 folder of our GitHub repository](https://github.com/paulboal/hds5210-2023/tree/main/week15) to connect your notebook either to Big Query or Snowflake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilnaR6ktiidb"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install \"snowflake-connector-python[pandas]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import snowflake.connector\n",
        "\n"
      ],
      "metadata": {
        "id": "K7lmKNq51PMn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DIABETES_PREDICTION = snowflake.connector.connect(\n",
        "    user='CHIMDINMA01',\n",
        "    password='Dinma2023',\n",
        "    account='VNPOEID-SP40827',\n",
        "    database='CHIMDI',\n",
        "    schema='PUBLIC',\n",
        "    warehouse='COMPUTE_WH',\n",
        "    session_parameters={\n",
        "        'QUERY_TAG': 'DIABETES_PREDICTION',\n",
        "    }\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "b2M0OXWy6V-p"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = ('diabetes_prediction_dataset.csv')"
      ],
      "metadata": {
        "id": "HCKgB6Jv1h-N"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4VYKE-Hiidb"
      },
      "source": [
        "### 2. Query some data\n",
        "\n",
        "Assuming the source database has some data in it or that you can load some data into it from any source, query it.  Then, read that data into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gRFBQ8xbiidb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('diabetes_prediction_dataset.csv')"
      ],
      "metadata": {
        "id": "miqIbUgkdkDd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import snowflake.connector\n",
        "# Query data from the DIABETES_PREDICTION table\n",
        "query = 'SELECT * FROM DIABETES_PREDICTION'\n",
        "df = pd.read_sql(query, DIABETES_PREDICTION)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI9be9cQEuwf",
        "outputId": "dc816ffe-b7a8-44be-c00c-04f74225f623"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-928c867374a9>:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df = pd.read_sql(query, DIABETES_PREDICTION)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   GENDER  AGE  HYPERTENSION  HEART_DISEASE SMOKING_HISTORY  BMI  HBA1C_LEVEL  \\\n",
            "0  Female   80             0              1           never   25            7   \n",
            "1  Female   54             0              0         No Info   27            7   \n",
            "2    Male   28             0              0           never   27            6   \n",
            "3  Female   36             0              0         current   23            5   \n",
            "4    Male   76             1              1         current   20            5   \n",
            "\n",
            "   BLOOD_GLUCOSE_LEVEL  DIABETES  \n",
            "0                  140         0  \n",
            "1                   80         0  \n",
            "2                  158         0  \n",
            "3                  155         0  \n",
            "4                  155         0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXqra7vziidc"
      },
      "source": [
        "### 3. Aggregate your data frame\n",
        "\n",
        "Do some kind of aggregation on your data frame.  Something that makes sense and has some groups to it.  Don't just sum up one column for the entire data frame.  Be more creative than that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeTIp5E_iidc",
        "outputId": "8a462f92-c0bf-4834-f6af-8b831a211c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   GENDER        AGE  BMI\n",
            "0  Female  56.666667   27\n",
            "1    Male  52.000000   27\n"
          ]
        }
      ],
      "source": [
        "#Aggregating a few columns of my data frame\n",
        "\n",
        "data = {\n",
        "    'GENDER': ['Female', 'Female', 'Male', 'Female', 'Male',],\n",
        "    'AGE': [80, 54, 28, 36, 76],\n",
        "    'BMI': [25, 27, 27, 23, 20],\n",
        "    'BLOOD_GLUCOSE_LEVEL': [140, 80, 158, 155, 155]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Perform aggregation\n",
        "aggregated_df = df.groupby('GENDER').agg({\n",
        "    'AGE': 'mean',   # Calculate average age\n",
        "    'BMI': 'max'     # Find maximum BMI\n",
        "}).reset_index()\n",
        "\n",
        "# Display the aggregated DataFrame\n",
        "print(aggregated_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljnuu6Odiidc"
      },
      "source": [
        "### 4. Write to Excel\n",
        "\n",
        "Use Pandas functions to write your summarized data out to a local Excel file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGlU1oMFiidc",
        "outputId": "88537aeb-27c1-4282-8636-5ab325e6b1c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been written to https://eu.docworkspace.com/d/sIK-uooeCAc_Yw6sG.xlsx\n"
          ]
        }
      ],
      "source": [
        "\n",
        "excel_file_path = 'https://eu.docworkspace.com/d/sIK-uooeCAc_Yw6sG.xlsx'\n",
        "\n",
        "# Write the summarized data to Excel\n",
        "aggregated_df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "print(f\"Data has been written to {excel_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UkOnulpfiidc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfyXjlKBiidc"
      },
      "source": [
        "---\n",
        "\n",
        "## Submitting Your Work\n",
        "\n",
        "Submit your work as usual"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}